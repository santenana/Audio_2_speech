{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0aa52fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 22:30:29.240324: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-02-07 22:30:29.266083: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2026-02-07 22:30:29.266110: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2026-02-07 22:30:29.266838: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2026-02-07 22:30:29.271297: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-02-07 22:30:29.962384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification \n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ordered_set import OrderedSet\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c5efe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONFIGURACIÃ“N DE TENSORFLOW 2.15.1 CON CUDA 12.2\n",
      "======================================================================\n",
      "\n",
      "GPUs disponibles: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-07 22:30:34.535837: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2026-02-07 22:30:34.537687: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"CONFIGURACIÃ“N DE TENSORFLOW 2.15.1 CON CUDA 12.2\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Verificar GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"\\nGPUs disponibles: {len(gpus)}\")\n",
    "for gpu in gpus:\n",
    "    print(f\"  - {gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1dd306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â¿Soporte CUDA?:  True\n",
      "No se detectÃ³ ninguna GPU. Revisa los drivers o la versiÃ³n de CUDA.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. Comprobar si TensorFlow fue compilado con soporte CUDA\n",
    "print(\"Â¿Soporte CUDA?: \", tf.test.is_built_with_cuda())\n",
    "\n",
    "# 2. Listar dispositivos fÃ­sicos (GPUs) detectados\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPUs detectadas: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\" - Nombre: {gpu}\")\n",
    "else:\n",
    "    print(\"No se detectÃ³ ninguna GPU. Revisa los drivers o la versiÃ³n de CUDA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcee9b",
   "metadata": {},
   "source": [
    "### **Carga Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74b0dc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43410, 3) (5426, 3) (5427, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('./Kaggle/Go_Emotions/data/train.tsv', sep='\\t', header=None, names=['text','labels', 'code'])\n",
    "validation_df = pd.read_csv('./Kaggle/Go_Emotions/data/dev.tsv', sep='\\t', header=None, names=['text','labels', 'code'])\n",
    "test_df = pd.read_csv('./Kaggle/Go_Emotions/data/test.tsv', sep='\\t', header=None, names=['text','labels', 'code'])\n",
    "\n",
    "print(train_df.shape, validation_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ff81f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(inplace=True, axis=1, labels=['code'])\n",
    "validation_df.drop(inplace=True, axis=1, labels=['code'])\n",
    "test_df.drop(inplace=True, axis=1, labels=['code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74e89c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'admiration', 1: 'amusement', 2: 'anger', 3: 'annoyance', 4: 'approval', 5: 'caring', 6: 'confusion', 7: 'curiosity', 8: 'desire', 9: 'disappointment', 10: 'disapproval', 11: 'disgust', 12: 'embarrassment', 13: 'excitement', 14: 'fear', 15: 'gratitude', 16: 'grief', 17: 'joy', 18: 'love', 19: 'nervousness', 20: 'optimism', 21: 'pride', 22: 'realization', 23: 'relief', 24: 'remorse', 25: 'sadness', 26: 'surprise', 27: 'neutral'}\n"
     ]
    }
   ],
   "source": [
    "decode_labels = {}\n",
    "i = 0\n",
    "with open('./Kaggle/Go_Emotions/data/emotions.txt', 'r') as decoding:\n",
    "    for line in decoding:\n",
    "        decode_labels[i] = line.strip()\n",
    "        i += 1\n",
    "print(decode_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff8d2ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoding(label):\n",
    "    label = list(map(int, label.split(',')))\n",
    "    decoded = []\n",
    "    for x in label:\n",
    "        decoded.append(decode_labels.get(x))\n",
    "    return decoded\n",
    "\n",
    "train_df['labels'] = train_df['labels'].apply(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b24566d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df['labels'] = validation_df['labels'].apply(decoding)\n",
    "test_df['labels'] = test_df['labels'].apply(decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c9486aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "goemotions_to_fer = {\n",
    "    \"anger\": \"angry\",\n",
    "    \"annoyance\": \"angry\",\n",
    "    \"disapproval\": \"angry\", \n",
    "\n",
    "    \"disgust\": \"disgust\",\n",
    "\n",
    "    \"fear\": \"fear\",\n",
    "    \"nervousness\": \"fear\",\n",
    "\n",
    "    \"admiration\": \"happy\",\n",
    "    \"amusement\": \"happy\",\n",
    "    \"approval\": \"happy\",\n",
    "    \"caring\": \"happy\",\n",
    "    \"excitement\": \"happy\",\n",
    "    \"gratitude\": \"happy\",\n",
    "    \"joy\": \"happy\",\n",
    "    \"love\": \"happy\",\n",
    "    \"optimism\": \"happy\",\n",
    "    \"pride\": \"happy\",\n",
    "    \"relief\": \"happy\",\n",
    "\n",
    "    \"disappointment\": \"sad\",\n",
    "    \"embarrassment\": \"sad\",\n",
    "    \"grief\": \"sad\",\n",
    "    \"remorse\": \"sad\",\n",
    "    \"sadness\": \"sad\",\n",
    "\n",
    "    \"surprise\": \"surprise\",\n",
    "    \"realization\": \"surprise\",\n",
    "    \"curiosity\": \"surprise\",  \n",
    "    \"confusion\": \"surprise\",\n",
    "\n",
    "    \"neutral\": \"neutral\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e737979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_fer(go_labels, mapping):\n",
    "    mapped = OrderedSet()\n",
    "    for label in go_labels:\n",
    "        if label in mapping:\n",
    "            mapped.add(mapping[label])\n",
    "    return list(mapped) if mapped else [\"neutral\"]  \n",
    "train_df['fer_labels'] = train_df['labels'].apply(lambda labs: map_to_fer(labs, goemotions_to_fer))\n",
    "validation_df['fer_labels'] = validation_df['labels'].apply(lambda labs: map_to_fer(labs, goemotions_to_fer))\n",
    "test_df['fer_labels'] = test_df['labels'].apply(lambda labs: map_to_fer(labs, goemotions_to_fer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "283c6c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer_labels\n",
      "happy       16935\n",
      "neutral     14608\n",
      "angry        5579\n",
      "surprise     5367\n",
      "sad          3263\n",
      "disgust       793\n",
      "fear          726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_labels = train_df['fer_labels'].explode().value_counts()\n",
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353ade22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['fer_label'] = train_df['fer_labels'].apply(lambda x: x[0])\n",
    "validation_df['fer_label'] = validation_df['fer_labels'].apply(lambda x: x[0])\n",
    "test_df['fer_label'] = test_df['fer_labels'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba48efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['sentiment_final'] = train_df['labels'].apply(lambda x: x[0])\n",
    "validation_df['sentiment_final'] = validation_df['labels'].apply(lambda x: x[0])\n",
    "test_df['sentiment_final'] = test_df['labels'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48bc7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict = {\n",
    "    \"angry\":0,\n",
    "    \"disgust\":1,\n",
    "    \"fear\":2,\n",
    "    \"happy\":3,\n",
    "    \"sad\":4,\n",
    "    \"surprise\":5,\n",
    "    \"neutral\":6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a51a66e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "train_df['label_id'] = [map_dict[i] for i in train_df['fer_label']]\n",
    "validation_df['label_id'] = [map_dict[i] for i in validation_df['fer_label']]\n",
    "test_df['label_id'] = [map_dict[i] for i in test_df['fer_label']]\n",
    "\n",
    "num_labels = len(map_dict)\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf7a5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df['text'].tolist()\n",
    "train_labels = train_df['label_id'].tolist()\n",
    "val_texts = validation_df['text'].tolist()\n",
    "val_labels = validation_df['label_id'].tolist()\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d47278d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_texts, train_labels))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((val_texts, val_labels))\n",
    "\n",
    "train_ds = train_ds.shuffle(1000).batch(8).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(8).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0df71312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(df, label_col):\n",
    "  min_count = df[label_col].value_counts().min()\n",
    "  min_count\n",
    "  df = (\n",
    "      df.groupby(label_col, group_keys=False)\n",
    "        .apply(lambda x: x.sample(min_count, random_state=42))\n",
    "        .reset_index(drop=True)\n",
    "  )\n",
    "  df.head()\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eedad2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, validation_df,test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0420337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = balance_classes(df, 'fer_label')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34deaeba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_final\n",
       "happy       20599\n",
       "neutral     16545\n",
       "angry        6729\n",
       "surprise     5593\n",
       "sad          3264\n",
       "fear          792\n",
       "disgust       741\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['labels', 'fer_labels', 'label_id','sentiment_final'])\n",
    "df = df.rename(columns={\"fer_label\": \"sentiment_final\"})    \n",
    "\n",
    "df['sentiment_final'].value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "640de9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My favourite food is anything I didn't have to...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now if he does off himself, everyone will thin...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WHY THE FUCK IS BAYLESS ISOING</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>To make her feel threatened</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dirty Southern Wankers</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_final\n",
       "0  My favourite food is anything I didn't have to...         neutral\n",
       "1  Now if he does off himself, everyone will thin...         neutral\n",
       "2                     WHY THE FUCK IS BAYLESS ISOING           angry\n",
       "3                        To make her feel threatened            fear\n",
       "4                             Dirty Southern Wankers           angry"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73eb7d2",
   "metadata": {},
   "source": [
    "### **Entrenamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e92a54",
   "metadata": {},
   "source": [
    "#### **DistilBERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c2da4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12708209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NÃºmero de emociones/clases: 7\n",
      "Clases: ['angry' 'disgust' 'fear' 'happy' 'neutral' 'sad' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['sentiment_final'])\n",
    "\n",
    "# NÃºmero de clases\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"NÃºmero de emociones/clases: {num_labels}\")\n",
    "print(f\"Clases: {label_encoder.classes_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e2f5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['label_encoded'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['label_encoded']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c85bbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Dataset personalizado para clasificaciÃ³n de emociones con DistilBERT\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenizar\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d352f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Cargando DistilBERT tokenizer...\n",
      "âœ… Datasets creados - Train: 43410, Val: 10853\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“¦ Cargando DistilBERT tokenizer...\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "train_dataset = EmotionDataset(\n",
    "    texts=train_texts,\n",
    "    labels=train_labels,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "val_dataset = EmotionDataset(\n",
    "    texts=val_texts,\n",
    "    labels=val_labels,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "print(f\"âœ… Datasets creados - Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08980760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DataLoaders creados - Batches por Ã©poca: 2714\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"âœ… DataLoaders creados - Batches por Ã©poca: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08348ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¦ Cargando modelo DistilBERT preentrenado...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a98e3bc639454abb57c18ff8be3b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mDistilBertForSequenceClassification LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "classifier.weight       | MISSING    | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Modelo cargado en cuda\n",
      "ðŸ“Š ParÃ¡metros totales: 66,958,855\n",
      "ðŸ“Š ParÃ¡metros entrenables: 66,958,855\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ“¦ Cargando modelo DistilBERT preentrenado...\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(f\"âœ… Modelo cargado en {device}\")\n",
    "\n",
    "# Mostrar parÃ¡metros del modelo\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"ðŸ“Š ParÃ¡metros totales: {total_params:,}\")\n",
    "print(f\"ðŸ“Š ParÃ¡metros entrenables: {trainable_params:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
